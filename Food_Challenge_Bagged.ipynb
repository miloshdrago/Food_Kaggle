{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Food_Challenge_Bagged.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorisvdv/Food_Kaggle_UvA/blob/master/Food_Challenge_Bagged.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LD11HOGgL-q5",
        "colab_type": "code",
        "outputId": "61102beb-57ca-4a85-9ccf-ad208a08f38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, load_model, model_from_json, Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, MaxPooling2D, Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "import os.path\n",
        "import fnmatch\n",
        "import itertools\n",
        "import functools\n",
        "from math import floor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#Different Models\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "# Additions for model Antonio\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import regularizers\n",
        "import json\n",
        "\n",
        "# Added ResNet model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oje2NJ3zTwqj",
        "colab_type": "text"
      },
      "source": [
        "# Download Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhEnbo7EUyZR",
        "colab_type": "code",
        "outputId": "9bbf5c4b-910c-4759-d35b-e390385e13a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Food\\ Kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Make output file for models\n",
        "!mkdir competitions/food-recognition-challenge/models\n",
        "\n",
        "from google.colab import files\n",
        "# !ls\n",
        "# print(\"Upload kaggle api credentials json\")\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "mkdir: cannot create directory ‘competitions/food-recognition-challenge/models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQsUjcgt2PkA",
        "colab_type": "code",
        "outputId": "57f671ba-4de6-44fd-e8bb-aa0bdea789c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# # Set up kaggle, for some reason this does not download all files.\n",
        "!pip install --upgrade --no-deps --force-reinstall  kaggle\n",
        "# !mkdir ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v /content\n",
        "\n",
        "!kaggle competitions download food-recognition-challenge\n",
        "# Unzip data\n",
        "!unzip -q -n competitions/food-recognition-challenge/food-recognition-challenge.zip -d competitions/food-recognition-challenge/\n",
        "!ls competitions/food-recognition-challenge/\n",
        "print(len([name for name in os.listdir('competitions/food-recognition-challenge/train_set/train_set')]))\n",
        "print(len([name for name in os.listdir('competitions/food-recognition-challenge/test_set/test_set')]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /root/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674/kaggle-1.5.6-cp36-none-any.whl\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.6\n",
            "    Uninstalling kaggle-1.5.6:\n",
            "      Successfully uninstalled kaggle-1.5.6\n",
            "Successfully installed kaggle-1.5.6\n",
            "- path is now set to: /content\n",
            "food-recognition-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "food-recognition-challenge.zip\tsample.csv\t  train_set\n",
            "i3_final.hdf5\t\t\tsubmission.csv\t  vgg_checkpoint.hdf5\n",
            "i3_top_checkpoint.hdf5\t\ttest_set\t  vgg_final.hdf5\n",
            "models\t\t\t\ttrain_labels.csv\n",
            "30612\n",
            "7653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUw_hLH-ErPF",
        "colab_type": "text"
      },
      "source": [
        "# General Settings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntx7w3TpEp0i",
        "colab_type": "code",
        "outputId": "bf12ddc4-a940-403c-925b-6928889a3b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Settings\n",
        "img_width, img_height = 224, 224\n",
        "i3_img_width, i3_img_height = 299, 299\n",
        "data = pd.read_csv('competitions/food-recognition-challenge/train_labels.csv',dtype=str)\n",
        "display(data.head())\n",
        "train_data_dir = 'competitions/food-recognition-challenge/train_set/train_set/'\n",
        "test_data_dir = 'competitions/food-recognition-challenge/test_set/test_set/'\n",
        "\n",
        "checkpoint_vgg= 'competitions/food-recognition-challenge/models/vgg_checkpoint.hdf5'\n",
        "final_vgg= 'competitions/food-recognition-challenge/models/vgg_final.hdf5'\n",
        "json_vgg = \"competitions/food-recognition-challenge/models/vgg_model.json\"\n",
        "weights_vgg = \"competitions/food-recognition-challenge/models/vgg_model_weights.h5\"\n",
        "\n",
        "checkpoint_top_i3 = 'competitions/food-recognition-challenge/models/i3_top_checkpoint.hdf5'\n",
        "checkpoint_full_i3 = 'competitions/food-recognition-challenge/models/i3_full_checkpoint.hdf5'\n",
        "final_i3= 'competitions/food-recognition-challenge/models/i3_final.hdf5'\n",
        "json_i3 = \"competitions/food-recognition-challenge/models/i3_model.json\"\n",
        "weights_i3 = \"competitions/food-recognition-challenge/models/i3_model_weights.h5\"\n",
        "\n",
        "checkpoint_top_resnet = 'competitions/food-recognition-challenge/models/resnet_top_checkpoint.hdf5'\n",
        "checkpoint_full_resnet = 'competitions/food-recognition-challenge/models/resnet_full_checkpoint.hdf5'\n",
        "final_resnet= 'competitions/food-recognition-challenge/models/resnet_final.hdf5'\n",
        "json_resnet = \"competitions/food-recognition-challenge/models/resnet_model.json\"\n",
        "weights_resnet = \"competitions/food-recognition-challenge/models/resnet_model_weights.h5\"\n",
        "\n",
        "submission_file = \"competitions/food-recognition-challenge/submission.csv\"\n",
        "\n",
        "epochs_top = 1\n",
        "epochs = 1\n",
        "batch_size = 64\n",
        "patience_num = 3\n",
        "\n",
        "# Load in model files\n",
        "vgg_model_file = False #\"../input/model-antonio-v4/model_more_fully.h5\"\n",
        "vgg_model_json_file = False #\"../input/model-antonio-v4/model_more_fully.json\"\n",
        "i3_model_file = False #\"../input/inception-food-model/trained_model.hdf5\"\n",
        "i3_model_json_file = False\n",
        "resnet_model_file = False #\"../input/inception-food-model/trained_model.hdf5\"\n",
        "resnet_model_json_file = False\n",
        "\n",
        "\n",
        "\n",
        "#Train-test split\n",
        "data_h, holdoutSet = train_test_split(data, test_size=0.1, random_state = 21)\n",
        "#Train-test split\n",
        "trainingSet, validationSet = train_test_split(data_h, test_size=0.2, random_state = 16)\n",
        "\n",
        "\n",
        "# Test flow_from_dataframe\n",
        "sample_csv = pd.read_csv('competitions/food-recognition-challenge/sample.csv',dtype=str)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_1.jpg</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_2.jpg</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_3.jpg</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_4.jpg</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_5.jpg</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      img_name label\n",
              "0  train_1.jpg    21\n",
              "1  train_2.jpg    29\n",
              "2  train_3.jpg    17\n",
              "3  train_4.jpg    21\n",
              "4  train_5.jpg    50"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkl80xDnF7kr",
        "colab_type": "text"
      },
      "source": [
        "# DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URivqoFiF_a7",
        "colab_type": "code",
        "outputId": "56b4b9e3-d451-4748-aad6-b3e61739d5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "# Create class weights\n",
        "\n",
        "class_w = class_weight.compute_class_weight('balanced', np.unique(trainingSet[\"label\"]), trainingSet[\"label\"])\n",
        "\n",
        "#VGG Loaders\n",
        "def preprocess_input_vgg(x):\n",
        "    \"\"\"Wrapper around keras.applications.vgg16.preprocess_input()\n",
        "    to make it compatible for use with keras.preprocessing.image.ImageDataGenerator's\n",
        "    `preprocessing_function` argument.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    x : a numpy 3darray (a single image to be preprocessed)\n",
        "    \n",
        "    Note we cannot pass keras.applications.vgg16.preprocess_input()\n",
        "    directly to to keras.preprocessing.image.ImageDataGenerator's\n",
        "    `preprocessing_function` argument because the former expects a\n",
        "    4D tensor whereas the latter expects a 3D tensor. Hence the\n",
        "    existence of this wrapper.\n",
        "    \n",
        "    Returns a numpy 3darray (the preprocessed image).\n",
        "    \n",
        "    \"\"\"\n",
        "    X = np.expand_dims(x, axis=0)\n",
        "    X = preprocess_input(X)\n",
        "    return X[0]\n",
        "\n",
        "vgg_train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "vgg_train_generator = vgg_train_datagen.flow_from_dataframe(\n",
        "    dataframe= trainingSet,\n",
        "    x_col=\"img_name\",\n",
        "    y_col=\"label\",\n",
        "    directory=train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    seed = 3)\n",
        "\n",
        "vgg_validation_train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n",
        "vgg_validation_generator = vgg_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= validationSet,\n",
        "    x_col=\"img_name\",\n",
        "    y_col=\"label\",\n",
        "    directory=train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    seed = 4)\n",
        "\n",
        "vgg_hold_generator = vgg_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= holdoutSet,\n",
        "    x_col=\"img_name\",\n",
        "    y_col=\"label\",\n",
        "    directory=train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=batch_size)\n",
        "\n",
        "vgg_test_generator = vgg_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= sample_csv,\n",
        "    x_col=\"img_name\",\n",
        "    y_col=\"label\",\n",
        "    directory=test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "vgg_train_samples = len(vgg_train_generator.filenames)\n",
        "vgg_validation_samples = len(vgg_validation_generator.filenames)\n",
        "\n",
        "print(\"vgg_Train files: \", len(vgg_train_generator.filenames))\n",
        "print(\"vgg_Validation files: \", len(vgg_validation_generator.filenames))\n",
        "print(\"i3_Holdout files: \", len(vgg_hold_generator.filenames))\n",
        "print(\"vgg_Test files: \", len(vgg_test_generator.filenames))\n",
        "\n",
        "vgg_mapping_indices = vgg_train_generator.class_indices\n",
        "print(vgg_mapping_indices)\n",
        "\n",
        "\n",
        "# Inception V3\n",
        "i3_train_datagen=ImageDataGenerator(rescale=1./255.,\n",
        "                              rotation_range=40,\n",
        "                              width_shift_range=0.2,\n",
        "                              height_shift_range=0.2,\n",
        "                              shear_range=0.2,\n",
        "                              zoom_range=0.2,\n",
        "                              horizontal_flip=True,\n",
        "                              fill_mode='nearest')\n",
        "\n",
        "i3_train_generator=i3_train_datagen.flow_from_dataframe(\n",
        "    dataframe= trainingSet,\n",
        "    directory=train_data_dir,\n",
        "    x_col=\"img_name\",\n",
        "    y_col='label',\n",
        "    batch_size=batch_size,\n",
        "    seed=5,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(i3_img_width, i3_img_height))\n",
        "\n",
        "i3_validation_train_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "i3_validation_generator=i3_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= validationSet,\n",
        "    directory=train_data_dir,\n",
        "    x_col=\"img_name\",\n",
        "    y_col='label',\n",
        "    batch_size=batch_size,\n",
        "    seed=6,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(i3_img_width, i3_img_height))\n",
        "\n",
        "i3_hold_generator = i3_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= holdoutSet,\n",
        "    directory=train_data_dir,\n",
        "    x_col=\"img_name\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(i3_img_width, i3_img_height),\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=batch_size)\n",
        "\n",
        "i3_test_generator = i3_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= sample_csv,\n",
        "    x_col=\"img_name\",\n",
        "    y_col=\"label\",\n",
        "    directory=test_data_dir,\n",
        "    target_size=(i3_img_width, i3_img_height),\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# filenames = test_generator.filenames\n",
        "# nb_samples = len(filenames)\n",
        "# print(nb_samples)\n",
        "\n",
        "i3_mapping_indices = i3_train_generator.class_indices\n",
        "\n",
        "i3_train_samples = len(i3_train_generator.filenames)\n",
        "i3_validation_samples = len(i3_validation_generator.filenames)\n",
        "\n",
        "print(\"i3_Train files: \", len(i3_train_generator.filenames))\n",
        "print(\"i3_Validation files: \", len(i3_validation_generator.filenames))\n",
        "print(\"i3_Holdout files: \", len(i3_hold_generator.filenames))\n",
        "print(\"i3_Test files: \", len(i3_test_generator.filenames))\n",
        "\n",
        "# resnet\n",
        "resnet_train_datagen=ImageDataGenerator(rescale=1./255.,\n",
        "                              rotation_range=40,\n",
        "                              width_shift_range=0.2,\n",
        "                              height_shift_range=0.2,\n",
        "                              shear_range=0.2,\n",
        "                              zoom_range=0.2,\n",
        "                              horizontal_flip=True,\n",
        "                              fill_mode='nearest')\n",
        "\n",
        "resnet_train_generator=resnet_train_datagen.flow_from_dataframe(\n",
        "    dataframe= trainingSet,\n",
        "    directory=train_data_dir,\n",
        "    x_col=\"img_name\",\n",
        "    y_col='label',\n",
        "    batch_size=batch_size,\n",
        "    seed=7,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(img_width, img_height))\n",
        "\n",
        "resnet_validation_train_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "resnet_validation_generator=resnet_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= validationSet,\n",
        "    directory=train_data_dir,\n",
        "    x_col=\"img_name\",\n",
        "    y_col='label',\n",
        "    batch_size=batch_size,\n",
        "    seed=8,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(img_width, img_height))\n",
        "\n",
        "resnet_hold_generator = resnet_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= holdoutSet,\n",
        "    directory=train_data_dir,\n",
        "    x_col=\"img_name\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(img_width, img_height),\n",
        "    shuffle=True,\n",
        "    seed=9,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=batch_size)\n",
        "\n",
        "resnet_test_generator = resnet_validation_train_datagen.flow_from_dataframe(\n",
        "    dataframe= sample_csv,\n",
        "    x_col=\"img_name\",\n",
        "    y_col=\"label\",\n",
        "    directory=test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "\n",
        "resnet_train_samples = len(resnet_train_generator.filenames)\n",
        "resnet_validation_samples = len(resnet_validation_generator.filenames)\n",
        "\n",
        "print(\"Resnet_Train files: \", len(resnet_train_generator.filenames))\n",
        "print(\"Resnet_Validation files: \", len(resnet_validation_generator.filenames))\n",
        "print(\"Resnet_Holdout files: \", len(resnet_hold_generator.filenames))\n",
        "print(\"Resnet_Test files: \", len(resnet_test_generator.filenames))\n",
        "\n",
        "resnet_mapping_indices = resnet_train_generator.class_indices\n",
        "\n",
        "if i3_mapping_indices == vgg_mapping_indices ==resnet_mapping_indices:\n",
        "  print(\"Indices match\")\n",
        "else:\n",
        "  print(\"Indices do not match\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22040 validated image filenames belonging to 80 classes.\n",
            "Found 5510 validated image filenames belonging to 80 classes.\n",
            "Found 3062 validated image filenames belonging to 80 classes.\n",
            "Found 7653 validated image filenames.\n",
            "vgg_Train files:  22040\n",
            "vgg_Validation files:  5510\n",
            "i3_Holdout files:  3062\n",
            "vgg_Test files:  7653\n",
            "{'1': 0, '10': 1, '11': 2, '12': 3, '13': 4, '14': 5, '15': 6, '16': 7, '17': 8, '18': 9, '19': 10, '2': 11, '20': 12, '21': 13, '22': 14, '23': 15, '24': 16, '25': 17, '26': 18, '27': 19, '28': 20, '29': 21, '3': 22, '30': 23, '31': 24, '32': 25, '33': 26, '34': 27, '35': 28, '36': 29, '37': 30, '38': 31, '39': 32, '4': 33, '40': 34, '41': 35, '42': 36, '43': 37, '44': 38, '45': 39, '46': 40, '47': 41, '48': 42, '49': 43, '5': 44, '50': 45, '51': 46, '52': 47, '53': 48, '54': 49, '55': 50, '56': 51, '57': 52, '58': 53, '59': 54, '6': 55, '60': 56, '61': 57, '62': 58, '63': 59, '64': 60, '65': 61, '66': 62, '67': 63, '68': 64, '69': 65, '7': 66, '70': 67, '71': 68, '72': 69, '73': 70, '74': 71, '75': 72, '76': 73, '77': 74, '78': 75, '79': 76, '8': 77, '80': 78, '9': 79}\n",
            "Found 22040 validated image filenames belonging to 80 classes.\n",
            "Found 5510 validated image filenames belonging to 80 classes.\n",
            "Found 3062 validated image filenames belonging to 80 classes.\n",
            "Found 7653 validated image filenames.\n",
            "i3_Train files:  22040\n",
            "i3_Validation files:  5510\n",
            "i3_Holdout files:  3062\n",
            "i3_Test files:  7653\n",
            "Found 22040 validated image filenames belonging to 80 classes.\n",
            "Found 5510 validated image filenames belonging to 80 classes.\n",
            "Found 3062 validated image filenames belonging to 80 classes.\n",
            "Found 7653 validated image filenames.\n",
            "Resnet_Train files:  22040\n",
            "Resnet_Validation files:  5510\n",
            "Resnet_Holdout files:  3062\n",
            "Resnet_Test files:  7653\n",
            "Indices match\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1qGcnQF4Gqk",
        "colab_type": "text"
      },
      "source": [
        "# Model VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saETRdAV4QzH",
        "colab_type": "code",
        "outputId": "6d17e7f3-4450-4d7b-a3c0-49e948708fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "if os.path.isfile(final_vgg):\n",
        "  vgg_model = load_model(final_vgg)\n",
        "elif os.path.isfile(vgg_model_file):\n",
        "  if os.path.isfile(vgg_model_json_file):\n",
        "    with open(vgg_model_json_file,'r') as f:\n",
        "      vgg_model = model_from_json(f.read())\n",
        "      vgg_model.load_weights(vgg_model_file)\n",
        "  else:\n",
        "    vgg_model = load_model(vgg_model_file)\n",
        "else:\n",
        "\n",
        "    vgg16 = VGG16(weights='imagenet', include_top = True)\n",
        "    vgg16.summary()\n",
        "    x  = vgg16.get_layer('fc2').output\n",
        "    # x = Flatten(name='flatten2')(x)\n",
        "    x = Dense(4096, activation='relu', name='d1')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(4096, activation='relu', name='d2')(x)\n",
        "    prediction = Dense(80, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    vgg_model = Model(inputs=vgg16.input, outputs=prediction)\n",
        "    vgg_model.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Freeze All Layers Except Bottleneck Layers for Fine-Tuning\n",
        "\n",
        "for layer in vgg_model.layers:\n",
        "    if layer.name in ['predictions', 'd1', 'd2', 'block4_conv3', 'block5_conv1', 'block5_conv2', 'block5_conv3']:\n",
        "        continue\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "df = pd.DataFrame(([layer.name, layer.trainable] \n",
        "                  for layer in vgg_model.layers), columns=['layer', 'trainable'])\n",
        "\n",
        "sgd = SGD(lr=1e-4, momentum=0.9, clipvalue = 0.5)\n",
        "\n",
        "vgg_model.compile(optimizer=sgd, \n",
        "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = vgg_model.to_json()\n",
        "with open(json_vgg, \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZew2B5YlGi7",
        "colab_type": "text"
      },
      "source": [
        "# Inception V3 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWQ3gIWpjs41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inception V3 model\n",
        "base_i3_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "if os.path.isfile(final_i3):\n",
        "  i3_model = load_model(final_i3)\n",
        "elif os.path.isfile(i3_model_file):\n",
        "  if os.path.isfile(i3_model_json_file):\n",
        "    with open(i3_model_json_file,'r') as f:\n",
        "      i3_model = model_from_json(f.read())\n",
        "      i3_model.load_weights(i3_model_file)\n",
        "  else:\n",
        "    i3_model = load_model(i3_model_file)\n",
        "else:\n",
        "\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_i3_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    # let's add a fully-connected layer (reduced from 1024 to 124)\n",
        "    x = Dense(124, activation='relu')(x)\n",
        "    # and a logistic layer, we have 80 classes\n",
        "    predictions = Dense(80, activation='softmax')(x)\n",
        "\n",
        "    i3_model = Model(inputs=base_i3_model.input, outputs=predictions)\n",
        "    \n",
        "    if i3_model_json_file:\n",
        "        with open(i3_model_json_file,'r') as f:\n",
        "            i3_model = model_from_json(f.read())\n",
        "        i3_model.load_weights(vgg_model_file)\n",
        "\n",
        "for layer in base_i3_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "i3_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = i3_model.to_json()\n",
        "with open(json_i3, \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9c_tsTKaQrT",
        "colab_type": "text"
      },
      "source": [
        "# Resnet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT9MlHi-aUl6",
        "colab_type": "code",
        "outputId": "e4c45a57-36c6-4312-8187-293d20882d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "base_res_model = ResNet50(include_top=False,\n",
        "               weights='imagenet')\n",
        "\n",
        "\n",
        "if os.path.isfile(final_resnet):\n",
        "  resnet_model = load_model(final_resnet)\n",
        "elif os.path.isfile(resnet_model_file):\n",
        "  if os.path.isfile(resnet_model_json_file):\n",
        "    with open(resnet_model_json_file,'r') as f:\n",
        "      resnet_model = model_from_json(f.read())\n",
        "      resnet_model.load_weights(resnet_model_file)\n",
        "  else:\n",
        "    resnet_model = load_model(resnet_model_file)\n",
        "else:\n",
        "\n",
        "  x = GlobalAveragePooling2D()(base_res_model.output)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  prediction = Dense(80, activation='softmax', name='predictions')(x)\n",
        "  resnet_model = Model(inputs=base_res_model.input, outputs=prediction)\n",
        "  #resnet_model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# display(df_resnet[140:])\n",
        "\n",
        "# warm up model\n",
        "for layer in base_res_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for i in range(-3,0):\n",
        "    resnet_model.layers[i].trainable = True\n",
        "df_resnet = pd.DataFrame(([layer.name, layer.trainable] \n",
        "                   for layer in resnet_model.layers), columns=['layer', 'trainable'])\n",
        "display(df_resnet[-6:])\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = resnet_model.to_json()\n",
        "with open(json_resnet, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>layer</th>\n",
              "      <th>trainable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>conv5_block3_out</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>global_average_pooling2d_1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>dense_3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>dropout_2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>dense_4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>predictions</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          layer  trainable\n",
              "174            conv5_block3_out      False\n",
              "175  global_average_pooling2d_1       True\n",
              "176                     dense_3       True\n",
              "177                   dropout_2       True\n",
              "178                     dense_4       True\n",
              "179                 predictions       True"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsKu4mYcgVP7",
        "colab_type": "text"
      },
      "source": [
        "# Train Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMGT4c7P4qsa",
        "colab_type": "code",
        "outputId": "7b310c6e-5133-4f7c-d7e2-6e220b10ae86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Train Model VGG\n",
        "\n",
        "#Save the model after every epoch.\n",
        "mc_vgg = ModelCheckpoint(checkpoint_vgg, monitor='val_acc', verbose=1, \n",
        "                         save_best_only=True, \n",
        "                         save_weights_only=False, mode='auto')\n",
        "\n",
        "es = EarlyStopping(monitor='val_acc', patience= patience_num,\n",
        "                   verbose=1, min_delta = 0.0005)\n",
        "\n",
        "\n",
        "vgg_history = vgg_model.fit_generator(\n",
        "        vgg_train_generator,\n",
        "        epochs= epochs,\n",
        "        validation_data= vgg_validation_generator,\n",
        "        # steps_per_epoch= vgg_train_samples // batch_size,\n",
        "        # validation_steps= vgg_validation_samples // batch_size,\n",
        "        class_weight=class_w,\n",
        "        callbacks=[mc_vgg, es])\n",
        "\n",
        "# serialize weights to HDF5\n",
        "vgg_model.save_weights(weights_vgg)\n",
        "\n",
        "vgg_model.save(final_vgg)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 87/345 [======>.......................] - ETA: 1:03 - loss: 2.4219 - acc: 0.3873\n",
            "Epoch 00001: val_acc improved from -inf to 0.38730, saving model to competitions/food-recognition-challenge/models/vgg_checkpoint.hdf5\n",
            "345/345 [==============================] - 288s 835ms/step - loss: 2.6509 - acc: 0.3445 - val_loss: 2.4219 - val_acc: 0.3873\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHLsHx0kkbQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train InceptionV3 top\n",
        "\n",
        "#Save the model after every epoch.\n",
        "mc_i3_top = ModelCheckpoint(checkpoint_top_i3, monitor='val_acc', verbose=1, \n",
        "                            save_best_only=True, \n",
        "                            save_weights_only=False, mode='auto')\n",
        "\n",
        "i3_top_history = i3_model.fit_generator(\n",
        "        i3_train_generator,\n",
        "        epochs= epochs_top,\n",
        "        validation_data= vgg_validation_generator,\n",
        "        steps_per_epoch=i3_train_samples // batch_size,\n",
        "        validation_steps=i3_validation_samples // batch_size,\n",
        "        class_weight=class_w,\n",
        "        callbacks=[mc_i3_top, es])\n",
        "\n",
        "# serialize weights to HDF5\n",
        "resnet_model.save_weights(weights_resnet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVoLDBwml7Ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train InceptionV3 full\n",
        "\n",
        "#Save the model after every epoch.\n",
        "mc_i3_full = ModelCheckpoint(checkpoint_full_i3, monitor='val_acc', verbose=1,\n",
        "                             save_best_only=True, \n",
        "                             save_weights_only=False, mode='auto')\n",
        "\n",
        "# Open up layers\n",
        "for layer in i3_model.layers[:249]:\n",
        "    layer.trainable = False\n",
        "for layer in i3_model.layers[249:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "i3_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
        "                 loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "i3_full_history = i3_model.fit_generator(\n",
        "        i3_train_generator,\n",
        "        epochs= epochs,\n",
        "        validation_data= i3_validation_generator,\n",
        "        steps_per_epoch=i3_train_samples // batch_size,\n",
        "        validation_steps=i3_validation_samples // batch_size,\n",
        "        class_weight=class_w,\n",
        "        callbacks=[mc_i3_top, es])\n",
        "\n",
        "\n",
        "# serialize weights to HDF5\n",
        "i3_model.save_weights(weights_i3)\n",
        "\n",
        "i3_model.save(final_i3)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv4wqkuXj33H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Resnet top\n",
        "\n",
        "#Save the model after every epoch.\n",
        "mc_resnet_top = ModelCheckpoint(checkpoint_top_resnet, monitor='val_acc', verbose=1, \n",
        "                            save_best_only=True, \n",
        "                            save_weights_only=False, mode='auto')\n",
        "\n",
        "i3_top_history = resnet_model.fit_generator(\n",
        "        resnet_train_generator,\n",
        "        epochs=  epochs_top,\n",
        "        validation_data= resnet_validation_generator,\n",
        "        steps_per_epoch=resnet_train_samples // batch_size,\n",
        "        validation_steps=resnet_validation_samples // batch_size,\n",
        "        class_weight=class_w,\n",
        "        callbacks=[mc_resnet_top, es])\n",
        "\n",
        "# serialize weights to HDF5\n",
        "resnet_model.save_weights(weights_i3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGooq18Bo2Y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Resnet full\n",
        "\n",
        "#Save the model after every epoch.\n",
        "mc_resnet_full = ModelCheckpoint(checkpoint_full_resnet, monitor='val_acc', verbose=1,\n",
        "                             save_best_only=True, \n",
        "                             save_weights_only=False, mode='auto')\n",
        "\n",
        "# Open up layers\n",
        "for layer in resnet_model.layers[:143]:\n",
        "    layer.trainable = False\n",
        "for layer in resnet_model.layers[143:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "resnet_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
        "                 loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "resnet_full_history = resnet_model.fit_generator(\n",
        "        resnet_train_generator,\n",
        "        epochs=  epochs,\n",
        "        validation_data= resnet_validation_generator,\n",
        "        steps_per_epoch=resnet_train_samples // batch_size,\n",
        "        validation_steps=resnet_validation_samples // batch_size,\n",
        "        class_weight=class_w,\n",
        "        callbacks=[mc_resnet_full, es])\n",
        "\n",
        "\n",
        "# serialize weights to HDF5\n",
        "resnet_model.save_weights(weights_resnet)\n",
        "\n",
        "resnet_model.save(final_resnet)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ace0UTk45OXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plots VGG16\n",
        "# Summarize history for accuracy\n",
        "plt.plot(vgg_history.history['acc'])\n",
        "plt.plot(vgg_history.history['val_acc'])\n",
        "plt.title('VGG16 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.savefig('vgg_acc_1.eps', format='eps', dpi=900)\n",
        "plt.show()\n",
        "\n",
        "# Summarize history for loss\n",
        "plt.plot(vgg_history.history['loss'])\n",
        "plt.plot(vgg_history.history['val_loss'])\n",
        "plt.title('VGG16 model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.savefig('vgg_val_1.eps', format='eps', dpi=900)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pKKKIp0XbaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plots Inception V3\n",
        "# Summarize history for accuracy\n",
        "plt.plot(i3_top_history.history['acc'])\n",
        "plt.plot(i3_top_history.history['val_acc'])\n",
        "plt.title('Inception V3 top model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('i3_top_acc_1.eps', format='eps', dpi=900)\n",
        "plt.show()\n",
        "\n",
        "# Summarize history for loss\n",
        "plt.plot(i3_top_history.history['loss'])\n",
        "plt.plot(i3_top_history.history['val_loss'])\n",
        "plt.title('Inception V3 top loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('i3_top_val_1.eps', format='eps', dpi=900)\n",
        "plt.show()\n",
        "\n",
        "# Plots\n",
        "# Summarize history for accuracy\n",
        "plt.plot(i3_full_history.history['acc'])\n",
        "plt.plot(i3_full_history.history['val_acc'])\n",
        "plt.title('Inception V3 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('i3_acc_1.eps', format='eps', dpi=900)\n",
        "plt.show()\n",
        "\n",
        "# Summarize history for loss\n",
        "plt.plot(i3_full_history.history['loss'])\n",
        "plt.plot(i3_full_history.history['val_loss'])\n",
        "plt.title('Inception V3 loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('i3_val_1.eps', format='eps', dpi=900)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHOIGJIhuzdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plots Resnet50\n",
        "# Summarize history for accuracy\n",
        "plt.plot(resnet_top_history.history['acc'])\n",
        "plt.plot(resnet_top_history.history['val_acc'])\n",
        "plt.title('Resnet 50 top model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('resnet_top_acc_1.eps', format='eps', dpi=900)\n",
        "plt.show()\n",
        "\n",
        "# Summarize history for loss\n",
        "plt.plot(resnet_top_history.history['loss'])\n",
        "plt.plot(resnet_top_history.history['val_loss'])\n",
        "plt.title('Resnet 50  top loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('resnet_top_val_1.eps', format='eps', dpi=900)\n",
        "plt.show()\n",
        "\n",
        "# Plots\n",
        "# Summarize history for accuracy\n",
        "plt.plot(resnet_full_history.history['acc'])\n",
        "plt.plot(resnet_full_history.history['val_acc'])\n",
        "plt.title('Resnet 50 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('resnet_acc_1.eps', format='eps', dpi=900)\n",
        "plt.show()\n",
        "\n",
        "# Summarize history for loss\n",
        "plt.plot(resnet_full_history.history['loss'])\n",
        "plt.plot(resnet_full_history.history['val_loss'])\n",
        "plt.title('Resnet 50 loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('resnet_val_1.eps', format='eps', dpi=900)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saLs9sFQSIaz",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut13N_wSSLYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_evaluate = vgg_model.evaluate_generator(vgg_hold_generator,verbose=1)\n",
        "print(vgg_evaluate)\n",
        "print(vgg_model.metrics_names)\n",
        "\n",
        "i3_evaluate = i3_model.evaluate_generator(i3_hold_generator,verbose=1)\n",
        "print(i3_evaluate)\n",
        "resnet_evaluate = resnet_model.evaluate_generator(resnet_hold_generator,verbose=1)\n",
        "print(i3_evaluate)\n",
        "\n",
        "total_performance = vgg_evaluate[1] + i3_evaluate[1] + resnet_evaluate[1]\n",
        "print(total_performance)\n",
        "weigth_vgg = vgg_evaluate[1]/total_performance\n",
        "weigth_i3 = i3_evaluate[1]/total_performance\n",
        "weigth_resnet = resnet_evaluate[1]/total_performance\n",
        "print(f\"\"\"Weight VGG Model: {weigth_vgg}\\n Weight Inception V3 Model: {weigth_i3}\n",
        "  \\n Weight Resnet Model: {weigth_resnet}\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNtZw4A3zdal",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue5zCphKDltN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG\n",
        "# Reset to ensure files are loaded in the correct order\n",
        "vgg_test_generator.reset()\n",
        "# Genarate predictions\n",
        "vgg_predict = vgg_model.predict_generator(vgg_test_generator, verbose = 1)\n",
        "\n",
        "# Test if amount of predictions match the number of examples\n",
        "print(\"Amount of predictions match the number of examples: \",\n",
        "      len(vgg_predict) == sample_csv.shape[0])\n",
        "\n",
        "# Inception V3\n",
        "# Reset to ensure files are loaded in the correct order\n",
        "i3_test_generator.reset()\n",
        "# Genarate predictions\n",
        "i3_predict = i3_model.predict_generator(i3_test_generator, verbose = 1)\n",
        "\n",
        "# Resnet\n",
        "# Reset to ensure files are loaded in the correct order\n",
        "resnet_test_generator.reset()\n",
        "# Genarate predictions\n",
        "resnet_predict = resnet_model.predict_generator(resnet_test_generator, verbose = 1)\n",
        "\n",
        "# Test if amount of predictions match the number of examples\n",
        "print(\"Amount of predictions match the number of examples: \",\n",
        "      len(vgg_predict) ==len(i3_predict) == len(resnet_predict) == sample_csv.shape[0])\n",
        "\n",
        "print(\"All indices match: \",\n",
        "      vgg_mapping_indices == i3_mapping_indices == resnet_mapping_indices)\n",
        "\n",
        "print(\"All filenames match: \",\n",
        "      resnet_test_generator.filenames == resnet_test_generator.filenames == resnet_test_generator.filenames)\n",
        "\n",
        "# Match highest scoring column index to label\n",
        "labels = dict((v,k) for k,v in vgg_mapping_indices.items())\n",
        "# Add labels of both models together\n",
        "total_predict = (vgg_predict*weigth_vgg  + i3_predict*weigth_i3 + resnet_predict*weigth_resnet)\n",
        "\n",
        "print(total_predict.shape)\n",
        "predictions = [labels[k] for k in np.argmax(total_predict,axis=1)]\n",
        "\n",
        "prediction = pd.DataFrame({\"img_name\": vgg_test_generator.filenames, \"label\":predictions})\n",
        "display(prediction.head())\n",
        "# Save submission as csv\n",
        "prediction.to_csv(submission_file, index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vasJYWgxUOTC",
        "colab_type": "text"
      },
      "source": [
        "# Save files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLbezQ2rUS0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls competitions/food-recognition-challenge/models\n",
        "!ls gdrive/My\\ Drive/Colab\\ Notebooks/Food\\ Kaggle\n",
        "!mkdir gdrive/My\\ Drive/Colab\\ Notebooks/Food\\ Kaggle/Model_files\n",
        "!cp competitions/food-recognition-challenge/models/* gdrive/My\\ Drive/Colab\\ Notebooks/Food\\ Kaggle/Model_files\n",
        "!ls gdrive/My\\ Drive/Colab\\ Notebooks/Food\\ Kaggle/Model_files\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIJ_zfJozr3p",
        "colab_type": "text"
      },
      "source": [
        "Submit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLz-Zzs-zuwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !kaggle competitions submit -c food-recognition-challenge -f competitions/food-recognition-challenge/submission.csv -m \"Submission using Google Colab, model Antonio, 200 epochs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81YvshOs0Nyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !kaggle competitions submissions -c food-recognition-challenge"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}